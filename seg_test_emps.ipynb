{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 做个小型测试  \n",
    "1. 直接用vgg16的模型做seg  \n",
    "2. 直接用encoder-decoder模块做seg  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存decoder预训练权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Input\n",
    "from ae_model import encoder_vgg16, decoder1_vgg16, decoder2_vgg16, decoder3_vgg16, encoder1_vgg16\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae_model = load_model('./grid-search/checkpoints/emps_models/', compile=False)\n",
    "ae_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "ins = Input(shape=(224, 224, 3))\n",
    "encoder_model = Model(ins, encoder_vgg16(ins))\n",
    "print(len(encoder_model.layers))\n",
    "##34"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l1, l2 in zip(encoder_model.layers[:34], ae_model.layers[0:34]):\n",
    "    l1.set_weights(l2.get_weights())\n",
    "\n",
    "ae_weight = ae_model.get_weights()[0][1]\n",
    "encoder_weight = encoder_model.get_weights()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "np.save('./grid-search/checkpoints/emps_models_encoder_weights_0_1.npy', encoder_weight) # for comparison\n",
    "encoder_model.save('./grid-search/checkpoints/emps_models_encoder_weights.h5') # for encoder-decoder test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_vgg16_model = tf.keras.models.Sequential(encoder_model.layers[:-2])\n",
    "encoder_vgg16_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weight = encoder_vgg16_model.get_weights()[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "encoder_vgg16_model.save('./grid-search/checkpoints/emps_models_encoder_vgg16_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 构建vgg16 并载入保存的权重"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_weight_model = Model(ins, encoder_vgg16(ins))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_model = tf.keras.models.Sequential(load_weight_model.layers[:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_model.load_weights('./grid-search/checkpoints/emps_models_encoder_vgg16_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both weights are identical\n"
     ]
    }
   ],
   "source": [
    "conn_model_weight = conn_model.get_weights()[0][1]\n",
    "compare_weight = np.load('./grid-search/checkpoints/emps_models_encoder_weights_0_1.npy')\n",
    "\n",
    "if conn_model_weight.all() == compare_weight.all():\n",
    "    print(\"Both weights are identical\")\n",
    "else: \n",
    "    print(\"Something wrong, weghts are different\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_14 (Conv2D)          (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " batch_normalization_14 (Bat  (None, 224, 224, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " batch_normalization_15 (Bat  (None, 224, 224, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 112, 112, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " batch_normalization_16 (Bat  (None, 112, 112, 128)    512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " batch_normalization_17 (Bat  (None, 112, 112, 128)    512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 56, 56, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 56, 56, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 56, 56, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 56, 56, 256)      1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 28, 28, 256)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_21 (Conv2D)          (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 28, 28, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_22 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 28, 28, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_23 (Conv2D)          (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 28, 28, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 14, 14, 512)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_24 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_24 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_25 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_25 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_26 (Conv2D)          (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " batch_normalization_26 (Bat  (None, 14, 14, 512)      2048      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 7, 7, 512)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              102764544 \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 4096)              16781312  \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 4097      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 134,281,537\n",
      "Trainable params: 134,273,089\n",
      "Non-trainable params: 8,448\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "conn_model.add(Flatten())\n",
    "conn_model.add(Dense(4096, activation='relu'))\n",
    "conn_model.add(Dense(4096, activation='relu'))\n",
    "conn_model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "conn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import segmentation_models as sm\n",
    "from keras.callbacks import TensorBoard\n",
    "from datetime import datetime\n",
    "\n",
    "logssss = './grid-search/logs/segmentation_test/pretrained_vgg16_' + datetime.now().strftime(\"%Y%m%d-%H%M%S\") \n",
    "conn_model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=[sm.metrics.iou_score])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.load('./grid-search/dataset-emps/npy/spilt_80train_20test/x_train.npy')\n",
    "y_train = np.load('./grid-search/dataset-emps/npy/spilt_80train_20test/y_train.npy')\n",
    "x_test = np.load('./grid-search/dataset-emps/npy/spilt_80train_20test/x_test.npy')\n",
    "y_test = np.load('./grid-search/dataset-emps/npy/spilt_80train_20test/y_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn_model.fit(x_train, y_train, verbose=1, batch_size=16, validation_data=(x_test, y_test), epochs=50, shuffle=False, callbacks=[TensorBoard(log_dir=logssss)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 问题  \n",
    "   ValueError: `logits` and `labels` must have the same shape, received ((None, 1) vs (None, 224, 224, 1)).    \n",
    "VGG16最原始的模型不能拿来这么用，我的数据不是这个结构。      \n",
    "Dense层出来的结构不一样.... 所以基本不能这么训练。   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
